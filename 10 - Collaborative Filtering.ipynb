{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/AhmedBaari/Big-Data-Analytics/blob/main/10%20-%20Collaborative%20Filtering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"wUPnrMfCvaIp"},"source":["# Experiment 10: Collaborative Filtering using Jaccard and Cosine Similarity with PySpark\n","\n","\n","## AIM\n","To implement collaborative filtering using Jaccard and Cosine similarity measures with PySpark for parallel computation."]},{"cell_type":"markdown","metadata":{"id":"_yXCKxI9vaIs"},"source":["## 1. Import Libraries and Start Spark"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b085LGxmvaIu","outputId":"c1860ebb-131f-4b93-e43d-5a004d46d975","executionInfo":{"status":"ok","timestamp":1761234686531,"user_tz":-330,"elapsed":9365,"user":{"displayName":"Varun Adhithya S","userId":"11694532361609819264"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Spark started successfully!\n"]}],"source":["# Import required libraries\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col, collect_set, size, array_intersect, array_union\n","from pyspark.sql.types import *\n","from pyspark.sql.functions import udf\n","import urllib.request\n","import zipfile\n","import math\n","\n","# Start Spark\n","spark = SparkSession.builder \\\n","    .appName(\"CollaborativeFiltering\") \\\n","    .getOrCreate()\n","\n","print(\"Spark started successfully!\")"]},{"cell_type":"markdown","metadata":{"id":"YWJ5CBvivaIv"},"source":["## 2. Download and Load MovieLens Dataset\n","In the lab exam, dataset will be provided locally, so this cell can be ignored."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LLfI50GivaIw","outputId":"efd38334-002a-4b6a-82d5-a0fad7a0cd47"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading MovieLens dataset...\n","Dataset downloaded and extracted!\n"]}],"source":["# Download MovieLens dataset\n","print(\"Downloading MovieLens dataset...\")\n","url = \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n","urllib.request.urlretrieve(url, \"ml-100k.zip\")\n","\n","# Extract the zip file\n","with zipfile.ZipFile(\"ml-100k.zip\", 'r') as zip_ref:\n","    zip_ref.extractall()\n","\n","print(\"Dataset downloaded and extracted!\")"]},{"cell_type":"markdown","source":["We'll use the below method of loading the dataset for our exam"],"metadata":{"id":"YFTqHv5Vv4MN"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pjmLZogJvaIx","outputId":"32aec77d-b744-4dbf-cc33-0c3792ca3b66"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded 100000 movie ratings\n","+------+-------+------+\n","|userId|movieId|rating|\n","+------+-------+------+\n","|   196|    242|   3.0|\n","|   186|    302|   3.0|\n","|    22|    377|   1.0|\n","|   244|     51|   2.0|\n","|   166|    346|   1.0|\n","+------+-------+------+\n","only showing top 5 rows\n","\n"]}],"source":["# Load ratings data\n","schema = StructType([\n","    StructField(\"userId\", IntegerType(), True),\n","    StructField(\"movieId\", IntegerType(), True),\n","    StructField(\"rating\", FloatType(), True),\n","    StructField(\"timestamp\", LongType(), True)\n","])\n","\n","ratings = spark.read.csv(\"ml-100k/u.data\", sep=\"\\t\", schema=schema)\n","ratings = ratings.drop(\"timestamp\") # Remove timestamp as we don't need it\n","\n","print(f\"Loaded {ratings.count()} movie ratings\")\n","ratings.show(5)"]},{"cell_type":"markdown","metadata":{"id":"tkHvKl6_vaIx"},"source":["## 3. Prepare Data for Similarity Calculation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kv98yQO_vaIy","outputId":"dcf5ccff-7a10-492f-97b2-edc8c812de4c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Created user preference sets for similarity calculation\n","+------+--------------------+\n","|userId|        liked_movies|\n","+------+--------------------+\n","|     1|[212, 183, 52, 13...|\n","|     2|[306, 285, 277, 3...|\n","|     3|[328, 307, 329, 3...|\n","|     4|[356, 357, 300, 3...|\n","|     5|[233, 102, 204, 1...|\n","+------+--------------------+\n","only showing top 5 rows\n","\n"]}],"source":["# Create user preference sets (movies with rating >= 3)\n","user_preferences = ratings.filter(col(\"rating\") >= 3) \\\n","    .groupBy(\"userId\") \\\n","    .agg(collect_set(\"movieId\").alias(\"liked_movies\"))\n","\n","print(\"Created user preference sets for similarity calculation\")\n","user_preferences.show(5)"]},{"cell_type":"markdown","metadata":{"id":"MNE-ENZ-vaIz"},"source":["## 4. Implement Jaccard Similarity with PySpark"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UIJgwZMsvaI0","outputId":"14454c30-df42-47b9-dfdb-0880986d95a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Jaccard similarity UDF created successfully!\n"]}],"source":["00# Define Jaccard similarity function\n","def jaccard_similarity(set1, set2):\n","    if not set1 or not set2:\n","        return 0.0\n","\n","    intersection = len(set(set1).intersection(set(set2)))\n","    union = len(set(set1).union(set(set2)))\n","\n","    return float(intersection) / union if union > 0 else 0.0\n","\n","# Register UDF for parallel execution\n","jaccard_udf = udf(jaccard_similarity, FloatType())\n","\n","print(\"Jaccard similarity UDF created successfully!\")"]},{"cell_type":"markdown","metadata":{"id":"wmH7zR_cvaI1"},"source":["## 5. Calculate User Similarities using Parallel Processing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"htobiw-OvaI2","outputId":"fa9c048f-6b78-46a1-9740-66344c025bd9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Calculated similarities using parallel processing:\n","+-----+-----+------------------+\n","|user1|user2|jaccard_similarity|\n","+-----+-----+------------------+\n","|  408|  898|         0.6896552|\n","|  328|  788|         0.6548043|\n","|  554|  764|         0.5217391|\n","|  674|  879|         0.5121951|\n","|  600|  826|               0.5|\n","+-----+-----+------------------+\n","only showing top 5 rows\n","\n"]}],"source":["# Create user pairs and calculate Jaccard similarity in parallel\n","user_pairs = user_preferences.alias(\"u1\").crossJoin(\n","    user_preferences.alias(\"u2\")\n",").filter(col(\"u1.userId\") < col(\"u2.userId\"))  # Avoid duplicate pairs\n","\n","# Calculate Jaccard similarities using PySpark for parallelization\n","similarities = user_pairs.select(\n","    col(\"u1.userId\").alias(\"user1\"),\n","    col(\"u2.userId\").alias(\"user2\"),\n","    jaccard_udf(col(\"u1.liked_movies\"), col(\"u2.liked_movies\")).alias(\"jaccard_similarity\")\n",")\n","\n","# Filter significant similarities\n","significant_similarities = similarities.filter(col(\"jaccard_similarity\") > 0.2)\n","\n","print(\"Calculated similarities using parallel processing:\")\n","significant_similarities.orderBy(col(\"jaccard_similarity\").desc()).show(5)"]},{"cell_type":"markdown","metadata":{"id":"Bk9cxmTevaI2"},"source":["## 6. Implement Cosine Similarity with PySpark"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KlJmiDBvvaI3","outputId":"aa8c2a29-7dea-4d4f-b97e-b009f1b5972a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cosine similarity UDF created successfully!\n","+-----+-----+-----------------+\n","|user1|user2|cosine_similarity|\n","+-----+-----+-----------------+\n","|  408|  898|        0.8164966|\n","|  328|  788|        0.7936492|\n","|  674|  879|       0.69047576|\n","|  554|  764|        0.6859943|\n","|  600|  826|       0.67951584|\n","+-----+-----+-----------------+\n","only showing top 5 rows\n","\n"]}],"source":["# Define Cosine similarity function\n","def cosine_similarity(set1, set2):\n","    if not set1 or not set2:\n","        return 0.0\n","\n","    intersection = len(set(set1).intersection(set(set2)))\n","    magnitude1 = math.sqrt(len(set1))\n","    magnitude2 = math.sqrt(len(set2))\n","\n","    return float(intersection) / (magnitude1 * magnitude2) if magnitude1 * magnitude2 > 0 else 0.0\n","\n","# Register Cosine UDF for parallel execution\n","cosine_udf = udf(cosine_similarity, FloatType())\n","\n","# Calculate Cosine similarities in parallel\n","cosine_similarities = user_pairs.select(\n","    col(\"u1.userId\").alias(\"user1\"),\n","    col(\"u2.userId\").alias(\"user2\"),\n","    cosine_udf(col(\"u1.liked_movies\"), col(\"u2.liked_movies\")).alias(\"cosine_similarity\")\n",")\n","\n","# Filter significant cosine similarities\n","significant_cosine = cosine_similarities.filter(col(\"cosine_similarity\") > 0.3)\n","\n","print(\"Cosine similarity UDF created successfully!\")\n","significant_cosine.orderBy(col(\"cosine_similarity\").desc()).show(5)"]},{"cell_type":"markdown","metadata":{"id":"ZeTu98OkvaI3"},"source":["## 7. Generate Recommendations"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t3KCgw89vaI3","outputId":"644b5cef-309f-4ef0-ecd0-aed328ec249d"},"outputs":[{"output_type":"stream","name":"stdout","text":["=== COLLABORATIVE FILTERING RESULTS ===\n","✓ Implemented Jaccard and Cosine similarity measures\n","✓ Used PySpark for parallel computation of similarities\n","✓ Processed user preferences efficiently across multiple cores\n","\n","Top similar user pairs (Jaccard):\n","+-----+-----+------------------+\n","|user1|user2|jaccard_similarity|\n","+-----+-----+------------------+\n","|  408|  898|         0.6896552|\n","|  328|  788|         0.6548043|\n","|  554|  764|         0.5217391|\n","+-----+-----+------------------+\n","only showing top 3 rows\n","\n","\n","Top similar user pairs (Cosine):\n","+-----+-----+-----------------+\n","|user1|user2|cosine_similarity|\n","+-----+-----+-----------------+\n","|  408|  898|        0.8164966|\n","|  328|  788|        0.7936492|\n","|  674|  879|       0.69047576|\n","+-----+-----+-----------------+\n","only showing top 3 rows\n","\n"]}],"source":["print(\"=== COLLABORATIVE FILTERING RESULTS ===\")\n","print(\"✓ Implemented Jaccard and Cosine similarity measures\")\n","print(\"✓ Used PySpark for parallel computation of similarities\")\n","print(\"✓ Processed user preferences efficiently across multiple cores\")\n","\n","# Show sample similar users using Jaccard similarity\n","print(\"\\nTop similar user pairs (Jaccard):\")\n","significant_similarities.orderBy(col(\"jaccard_similarity\").desc()).show(3)\n","\n","print(\"\\nTop similar user pairs (Cosine):\")\n","significant_cosine.orderBy(col(\"cosine_similarity\").desc()).show(3)"]},{"cell_type":"markdown","source":["## 8. Clean Up"],"metadata":{"id":"0e1yfGEJwhND"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"cleanup_cell","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d563d99f-429a-4d9d-fc6e-7d349c5a64c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Experiment completed successfully!\n"]}],"source":["# Stop Spark\n","spark.stop()\n","print(\"Experiment completed successfully!\")"]},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col, collect_set, udf\n","from pyspark.sql.types import FloatType\n","import math\n","\n","# Start Spark\n","spark = SparkSession.builder.appName(\"CollaborativeFiltering\").getOrCreate()\n","\n","# Load ratings data\n","ratings = spark.read.csv(\"ml-100k/u.data\", sep=\"\\t\",\n","                         schema=\"userId INT, movieId INT, rating FLOAT, timestamp LONG\") \\\n","                  .drop(\"timestamp\")\n","\n","# Create user preference sets (movies with rating >= 3)\n","user_prefs = ratings.filter(col(\"rating\") >= 3) \\\n","                   .groupBy(\"userId\") \\\n","                   .agg(collect_set(\"movieId\").alias(\"liked_movies\"))\n","\n","# Jaccard Similarity UDF\n","jaccard_udf = udf(lambda s1, s2: len(set(s1) & set(s2)) / len(set(s1) | set(s2))\n","                  if s1 and s2 else 0.0, FloatType())\n","\n","# Cosine Similarity UDF\n","cosine_udf = udf(lambda s1, s2: len(set(s1) & set(s2)) / (math.sqrt(len(s1)) * math.sqrt(len(s2)))\n","                 if s1 and s2 else 0.0, FloatType())\n","\n","# Calculate similarities in parallel\n","u1, u2 = user_prefs.alias(\"u1\"), user_prefs.alias(\"u2\")\n","pairs = u1.crossJoin(u2).filter(col(\"u1.userId\") < col(\"u2.userId\"))\n","\n","similarities = pairs.select(\n","    col(\"u1.userId\").alias(\"user1\"),\n","    col(\"u2.userId\").alias(\"user2\"),\n","    jaccard_udf(col(\"u1.liked_movies\"), col(\"u2.liked_movies\")).alias(\"jaccard_similarity\"),\n","    cosine_udf(col(\"u1.liked_movies\"), col(\"u2.liked_movies\")).alias(\"cosine_similarity\")\n",")\n","\n","# Show top similarities\n","print(\"Top Jaccard similarities:\")\n","similarities.orderBy(col(\"jaccard_similarity\").desc()).show(5)\n","\n","print(\"Top Cosine similarities:\")\n","similarities.orderBy(col(\"cosine_similarity\").desc()).show(5)\n","\n","spark.stop()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"HufXucZ5W-Vj","executionInfo":{"status":"error","timestamp":1761194307678,"user_tz":-330,"elapsed":19795,"user":{"displayName":"Dharun S K","userId":"03008018011579679786"}},"outputId":"84177e24-9b14-4389-f76c-24ef9707c2eb"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AnalysisException","evalue":"[PATH_NOT_FOUND] Path does not exist: file:/content/ml-100k/u.data.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4151661435.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Load ratings data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m ratings = spark.read.csv(\"ml-100k/u.data\", sep=\"\\t\", \n\u001b[0m\u001b[1;32m     11\u001b[0m                          schema=\"userId INT, movieId INT, rating FLOAT, timestamp LONG\") \\\n\u001b[1;32m     12\u001b[0m                   \u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"timestamp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAnalysisException\u001b[0m: [PATH_NOT_FOUND] Path does not exist: file:/content/ml-100k/u.data."]}]},{"cell_type":"code","source":[],"metadata":{"id":"OjFXD1DbXAGb"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}